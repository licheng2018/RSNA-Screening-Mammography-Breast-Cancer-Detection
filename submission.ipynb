{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This is the submission code of \"RSNA Screening Mammography Breast Cancer Detection\"\n",
    "\n",
    "Reference:\n",
    "https://www.kaggle.com/code/christofhenkel/se-resnext50-full-gpu-decoding\n",
    "\n",
    "https://www.kaggle.com/code/markwijkhuizen/rsna-efficientnetv2-training-tensorflow-tpu\n",
    "\n",
    "https://www.kaggle.com/code/markwijkhuizen/rsna-cropped-tfrecords-768x1344-dataset\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with installing pip requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q timm==0.6.5 --no-index --find-links=/kaggle/input/rsna-bc-pip-requirements\n",
    "!pip install -q albumentations==1.2.1 --no-index --find-links=/kaggle/input/rsna-bc-pip-requirements\n",
    "!pip install -q pylibjpeg-libjpeg==1.3.1 --no-index --find-links=/kaggle/input/rsna-bc-pip-requirements\n",
    "# !pip install -q pydicom==2.0.0 --no-index --find-links=/kaggle/input/rsna-bc-pip-requirements\n",
    "!pip install -q python-gdcm==3.0.20 --no-index --find-links=/kaggle/input/rsna-bc-pip-requirements\n",
    "!pip install -q dicomsdl==0.109.1 --no-index --find-links=/kaggle/input/rsna-bc-pip-requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the latest DALI packaging which we will use for GPU decoding\n",
    "!pip install -q /kaggle/input/nvidia-dali-nightly-cuda110-1230dev/nvidia_dali_nightly_cuda110-1.23.0.dev20230203-7187866-py3-none-manylinux2014_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Keras CV Attention Model Pip Package for ConvNextV2 Models\n",
    "!pip install --no-deps /kaggle/input/keras-cv-attention-models/keras_cv_attention_models-1.3.9-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to patch DALI for Int16 support\n",
    "from nvidia.dali.backend import TensorGPU, TensorListGPU\n",
    "from nvidia.dali.pipeline import Pipeline\n",
    "import nvidia.dali.ops as ops\n",
    "from nvidia.dali import types\n",
    "from nvidia.dali.plugin.base_iterator import _DaliBaseIterator\n",
    "from nvidia.dali.plugin.base_iterator import LastBatchPolicy\n",
    "import torch\n",
    "import torch.utils.dlpack as torch_dlpack\n",
    "import ctypes\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import pydicom\n",
    "\n",
    "to_torch_type = {\n",
    "    types.DALIDataType.FLOAT:   torch.float32,\n",
    "    types.DALIDataType.FLOAT64: torch.float64,\n",
    "    types.DALIDataType.FLOAT16: torch.float16,\n",
    "    types.DALIDataType.UINT8:   torch.uint8,\n",
    "    types.DALIDataType.INT8:    torch.int8,\n",
    "    types.DALIDataType.UINT16:  torch.int16,\n",
    "    types.DALIDataType.INT16:   torch.int16,\n",
    "    types.DALIDataType.INT32:   torch.int32,\n",
    "    types.DALIDataType.INT64:   torch.int64\n",
    "}\n",
    "\n",
    "\n",
    "def feed_ndarray(dali_tensor, arr, cuda_stream=None):\n",
    "    \"\"\"\n",
    "    Copy contents of DALI tensor to PyTorch's Tensor.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    `dali_tensor` : nvidia.dali.backend.TensorCPU or nvidia.dali.backend.TensorGPU\n",
    "                    Tensor from which to copy\n",
    "    `arr` : torch.Tensor\n",
    "            Destination of the copy\n",
    "    `cuda_stream` : torch.cuda.Stream, cudaStream_t or any value that can be cast to cudaStream_t.\n",
    "                    CUDA stream to be used for the copy\n",
    "                    (if not provided, an internal user stream will be selected)\n",
    "                    In most cases, using pytorch's current stream is expected (for example,\n",
    "                    if we are copying to a tensor allocated with torch.zeros(...))\n",
    "    \"\"\"\n",
    "    dali_type = to_torch_type[dali_tensor.dtype]\n",
    "\n",
    "    assert dali_type == arr.dtype, (\"The element type of DALI Tensor/TensorList\"\n",
    "                                    \" doesn't match the element type of the target PyTorch Tensor: \"\n",
    "                                    \"{} vs {}\".format(dali_type, arr.dtype))\n",
    "    assert dali_tensor.shape() == list(arr.size()), \\\n",
    "        (\"Shapes do not match: DALI tensor has size {0}, but PyTorch Tensor has size {1}\".\n",
    "            format(dali_tensor.shape(), list(arr.size())))\n",
    "    cuda_stream = types._raw_cuda_stream(cuda_stream)\n",
    "\n",
    "    # turn raw int to a c void pointer\n",
    "    c_type_pointer = ctypes.c_void_p(arr.data_ptr())\n",
    "    if isinstance(dali_tensor, (TensorGPU, TensorListGPU)):\n",
    "        stream = None if cuda_stream is None else ctypes.c_void_p(cuda_stream)\n",
    "        dali_tensor.copy_to_external(c_type_pointer, stream, non_blocking=True)\n",
    "    else:\n",
    "        dali_tensor.copy_to_external(c_type_pointer)\n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import multiprocessing as mp\n",
    "\n",
    "COMP_FOLDER = '/kaggle/input/rsna-breast-cancer-detection/'\n",
    "DATA_FOLDER = COMP_FOLDER + 'test_images/'\n",
    "\n",
    "sample_submission = pd.read_csv(COMP_FOLDER + 'sample_submission.csv')\n",
    "\n",
    "PUBLIC_RUN = len(sample_submission) == 2\n",
    "\n",
    "N_CORES = mp.cpu_count()\n",
    "MIXED_PRECISION = False\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "RAM_CHECK = False\n",
    "DEBUG = False\n",
    "\n",
    "test_df = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/test.csv')\n",
    "test_df['cancer'] = 0 #dummy value\n",
    "\n",
    "\n",
    "if PUBLIC_RUN is False:\n",
    "    RAM_CHECK = False\n",
    "    DEBUG = False\n",
    "\n",
    "if RAM_CHECK is True:\n",
    "    test_df = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv')[:50]\n",
    "    \n",
    "    test_df = test_df[test_df.image_id!=1942326353].reset_index(drop=True)\n",
    "    print(test_df.shape)\n",
    "    \n",
    "    patient_filter = list(sorted((set(test_df.patient_id.unique()))))\n",
    "    test_df = test_df[test_df.patient_id.isin(patient_filter)]\n",
    "    DATA_FOLDER = DATA_FOLDER.replace('test','train')\n",
    "\n",
    "if DEBUG is True:\n",
    "    test_df = test_df.head(500)\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Len df : {len(test_df)}')\n",
    "test_df['patient_id'].nunique()\n",
    "test_df[\"fns\"] = test_df['patient_id'].astype(str) + '/' + test_df['image_id'].astype(str) + '.dcm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define the function for GPU-based decoding using DALI and processing the dicom images\n",
    "import dicomsdl\n",
    "import pydicom\n",
    "from pydicom.filebase import DicomBytesIO\n",
    "\n",
    "import nvidia.dali.fn as fn\n",
    "import nvidia.dali.types as types\n",
    "from nvidia.dali import pipeline_def\n",
    "from nvidia.dali.types import DALIDataType\n",
    "\n",
    "\n",
    "def convert_dicom_to_jpg(file, save_folder=\"\"):\n",
    "    patient = file.split('/')[-2]\n",
    "    image = file.split('/')[-1][:-4]\n",
    "    dcmfile = pydicom.dcmread(file)\n",
    "\n",
    "    if dcmfile.file_meta.TransferSyntaxUID == '1.2.840.10008.1.2.4.90':\n",
    "        with open(file, 'rb') as fp:\n",
    "            raw = DicomBytesIO(fp.read())\n",
    "            ds = pydicom.dcmread(raw)\n",
    "        offset = ds.PixelData.find(b\"\\x00\\x00\\x00\\x0C\")  #<---- the jpeg2000 header info we're looking for\n",
    "        hackedbitstream = bytearray()\n",
    "        hackedbitstream.extend(ds.PixelData[offset:])\n",
    "        with open(save_folder + f\"{patient}_{image}.jpg\", \"wb\") as binary_file:\n",
    "            binary_file.write(hackedbitstream)\n",
    "            \n",
    "    if dcmfile.file_meta.TransferSyntaxUID == '1.2.840.10008.1.2.4.70':\n",
    "        with open(file, 'rb') as fp:\n",
    "            raw = DicomBytesIO(fp.read())\n",
    "            ds = pydicom.dcmread(raw)\n",
    "        offset = ds.PixelData.find(b\"\\xff\\xd8\\xff\\xe0\")  #<---- the jpeg lossless header info we're looking for\n",
    "        hackedbitstream = bytearray()\n",
    "        hackedbitstream.extend(ds.PixelData[offset:])\n",
    "        with open(save_folder + f\"{patient}_{image}.jpg\", \"wb\") as binary_file:\n",
    "            binary_file.write(hackedbitstream)\n",
    "\n",
    "            \n",
    "@pipeline_def\n",
    "def jpg_decode_pipeline(jpgfiles):\n",
    "    jpegs, _ = fn.readers.file(files=jpgfiles)\n",
    "    images = fn.experimental.decoders.image(jpegs, device = 'mixed', output_type = types.ANY_DATA, dtype = DALIDataType.UINT16)\n",
    "    return images\n",
    "\n",
    "def parse_window_element(elem):\n",
    "    if type(elem) == list:\n",
    "        return float(elem[0])\n",
    "    if type(elem) == str:\n",
    "        return float(elem)\n",
    "    if type(elem) == float:\n",
    "        return elem\n",
    "    if type(elem) == pydicom.dataelem.DataElement:\n",
    "        try:\n",
    "            return float(elem[0])\n",
    "        except:\n",
    "            return float(elem.value)\n",
    "    return None\n",
    "\n",
    "def linear_window(data, center, width):\n",
    "    lower, upper = center - width // 2, center + width // 2\n",
    "    data = torch.clamp(data, min = lower, max = upper)\n",
    "    return data \n",
    "\n",
    "def process_dicom(img, dicom):\n",
    "    try:\n",
    "        invert = getattr(dicom, \"PhotometricInterpretation\", None) == \"MONOCHROME1\"\n",
    "    except:\n",
    "        invert = False\n",
    "        \n",
    "    center = parse_window_element(dicom[\"WindowCenter\"]) \n",
    "    width = parse_window_element(dicom[\"WindowWidth\"])\n",
    "        \n",
    "    if (center is not None) & (width is not None):\n",
    "        img = linear_window(img, center, width)\n",
    "\n",
    "    img = (img - img.min()) / (img.max() - img.min())\n",
    "    if invert:\n",
    "        img = 1 - img\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "from typing import Any, Dict\n",
    "\n",
    "cfg = SimpleNamespace(**{})\n",
    "cfg.img_size = 1024\n",
    "cfg.backbone = 'seresnext50_32x4d'\n",
    "cfg.pretrained=False\n",
    "cfg.in_channels = 1\n",
    "cfg.classes = ['cancer']\n",
    "cfg.batch_size = 8\n",
    "cfg.data_folder = \"/tmp/output/\"\n",
    "cfg.val_aug = A.CenterCrop(always_apply=False, p=1.0, height=cfg.img_size, width=cfg.img_size)\n",
    "cfg.device = DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will process the dicoms in chunks so the disk space does not become an issue.\n",
    "import os\n",
    "SAVE_SIZE = int(cfg.img_size * 1.125)\n",
    "SAVE_FOLDER = cfg.data_folder\n",
    "os.makedirs(SAVE_FOLDER, exist_ok=True)\n",
    "N_CHUNKS = len(test_df[\"fns\"]) // 2000 if len(test_df[\"fns\"]) > 2000 else 1\n",
    "CHUNKS = [(len(test_df[\"fns\"]) / N_CHUNKS * k, len(test_df[\"fns\"]) / N_CHUNKS * (k + 1)) for k in range(N_CHUNKS)]\n",
    "CHUNKS = np.array(CHUNKS).astype(int)\n",
    "JPG_FOLDER = \"/tmp/jpg/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library needed for model1\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Any\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import timm\n",
    "import cv2\n",
    "import numpy as np\n",
    "import gc\n",
    "import glob\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "from types import SimpleNamespace\n",
    "import albumentations as A\n",
    "import multiprocessing as mp\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "N_CORES = mp.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = SimpleNamespace(**{})\n",
    "cfg.img_size = 1024\n",
    "cfg.backbone = 'seresnext50_32x4d'\n",
    "cfg.pretrained=False\n",
    "cfg.in_channels = 1\n",
    "cfg.classes = ['cancer']\n",
    "cfg.batch_size = 8\n",
    "cfg.data_folder = \"/tmp/output/\"\n",
    "cfg.val_aug = A.CenterCrop(always_apply=False, p=1.0, height=cfg.img_size, width=cfg.img_size)\n",
    "cfg.device = DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will process the dicoms in chunks so the disk space does not become an issue.\n",
    "SAVE_SIZE = int(cfg.img_size * 1.125)\n",
    "SAVE_FOLDER = cfg.data_folder\n",
    "os.makedirs(SAVE_FOLDER, exist_ok=True)\n",
    "N_CHUNKS = len(test_df[\"fns\"]) // 2000 if len(test_df[\"fns\"]) > 2000 else 1\n",
    "CHUNKS = [(len(test_df[\"fns\"]) / N_CHUNKS * k, len(test_df[\"fns\"]) / N_CHUNKS * (k + 1)) for k in range(N_CHUNKS)]\n",
    "CHUNKS = np.array(CHUNKS).astype(int)\n",
    "JPG_FOLDER = \"/tmp/jpg/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil \n",
    "from joblib import Parallel, delayed\n",
    "for ttt, chunk in enumerate(CHUNKS):\n",
    "    print(f'chunk {ttt} of {len(CHUNKS)} chunks')\n",
    "    os.makedirs(JPG_FOLDER, exist_ok=True)\n",
    "\n",
    "    _ = Parallel(n_jobs=2)(\n",
    "        delayed(convert_dicom_to_jpg)(f'{DATA_FOLDER}/{img}', save_folder=JPG_FOLDER)\n",
    "        for img in test_df[\"fns\"].tolist()[chunk[0]: chunk[1]]\n",
    "    )\n",
    "    \n",
    "    jpgfiles = glob.glob(JPG_FOLDER + \"*.jpg\")\n",
    "\n",
    "\n",
    "    pipe = jpg_decode_pipeline(jpgfiles, batch_size=1, num_threads=2, device_id=0)\n",
    "    pipe.build()\n",
    "\n",
    "    for i, f in enumerate(tqdm(jpgfiles)):\n",
    "        \n",
    "        patient, dicom_id = f.split('/')[-1][:-4].split('_')\n",
    "        dicom = pydicom.dcmread(DATA_FOLDER + f\"/{patient}/{dicom_id}.dcm\")\n",
    "        try:\n",
    "            out = pipe.run()\n",
    "            # Dali -> Torch\n",
    "            img = out[0][0]\n",
    "            img_torch = torch.empty(img.shape(), dtype=torch.int16, device=\"cuda\")\n",
    "            feed_ndarray(img, img_torch, cuda_stream=torch.cuda.current_stream(device=0))\n",
    "            img = img_torch.float()\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "            #apply dicom preprocessing\n",
    "            img = process_dicom(img, dicom)\n",
    "\n",
    "            #resize the torch image\n",
    "            img = F.interpolate(img.view(1, 1, img.size(0), img.size(1)), (SAVE_SIZE, SAVE_SIZE), mode=\"bilinear\")[0, 0]\n",
    "\n",
    "            img = (img * 255).clip(0,255).to(torch.uint8).cpu().numpy()\n",
    "            out_file_name = SAVE_FOLDER + f\"{patient}_{dicom_id}.png\"\n",
    "            cv2.imwrite(out_file_name, img)\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(i, e)\n",
    "            pipe = jpg_decode_pipeline(jpgfiles[i+1:], batch_size=1, num_threads=2, device_id=0)\n",
    "            pipe.build()\n",
    "            continue\n",
    "\n",
    "    shutil.rmtree(JPG_FOLDER)\n",
    "print(f'DALI Raw image load complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = glob.glob(f'{SAVE_FOLDER}/*.png')\n",
    "n_saved = len(fns)\n",
    "print(f'Image on disk count : {n_saved}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_processed_files = [fn.split('/')[-1].replace('_','/').replace('png','dcm') for fn in fns]\n",
    "to_process = [f for f in test_df[\"fns\"].values if f not in gpu_processed_files]\n",
    "len(gpu_processed_files), len(to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(f, save_folder=\"\"):\n",
    "    patient = f.split('/')[-2]\n",
    "    dicom_id = f.split('/')[-1][:-4]\n",
    "    \n",
    "    dicom = dicomsdl.open(f)\n",
    "    img = dicom.pixelData()\n",
    "    img = torch.from_numpy(img)\n",
    "    img = process_dicom(img, dicom)\n",
    "    \n",
    "    img = F.interpolate(img.view(1, 1, img.size(0), img.size(1)), (SAVE_SIZE, SAVE_SIZE), mode=\"bilinear\")[0, 0]\n",
    "\n",
    "    img = (img * 255).clip(0,255).to(torch.uint8).cpu().numpy()\n",
    "    out_file_name = SAVE_FOLDER + f\"{patient}_{dicom_id}.png\"\n",
    "    cv2.imwrite(out_file_name, img)\n",
    "    return out_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_processed_filenames = Parallel(n_jobs=2)(\n",
    "    delayed(process)(f'{DATA_FOLDER}/{img}', save_folder=SAVE_FOLDER)\n",
    "    for img in tqdm(to_process)\n",
    ")\n",
    "cpu_processed_filenames = [f for f in cpu_processed_filenames if f]\n",
    "print(f'CPU Raw image load complete with {len(cpu_processed_filenames)} loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_saved = len(glob.glob(f'{SAVE_FOLDER}/*.png'))\n",
    "print(f'Image on disk count : {n_saved}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert n_saved == len(test_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "\n",
    "def batch_to_device(batch, device):\n",
    "    batch_dict = {key: batch[key].to(device) for key in batch}\n",
    "    return batch_dict\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, cfg, aug):\n",
    "\n",
    "        self.cfg = cfg\n",
    "        self.df = df.copy()\n",
    "        self.df = self.df[self.df['image_id'].astype(str) != '1942326353']\n",
    "        self.labels = self.df[self.cfg.classes].values\n",
    "        self.df[\"fns\"] = self.df['patient_id'].astype(str) + '_' + self.df['image_id'].astype(str) + '.png'\n",
    "        self.fns = self.df[\"fns\"].astype(str).values\n",
    "        self.aug = aug\n",
    "        self.data_folder = cfg.data_folder\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        img = self.load_one(idx)\n",
    "\n",
    "        if self.aug:\n",
    "            img = self.augment(img)\n",
    "\n",
    "        img = self.normalize_img(img)\n",
    "        torch_img = torch.tensor(img).float().permute(2,0,1)\n",
    "        \n",
    "        feature_dict = {\n",
    "            \"input\": torch_img,\n",
    "            \"target\": torch.tensor(label),\n",
    "        }\n",
    "        return feature_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fns)\n",
    "\n",
    "    def load_one(self, idx):\n",
    "        path = self.data_folder + self.fns[idx]\n",
    "        try:\n",
    "            img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "            shape = img.shape\n",
    "            if len(img.shape) == 2:\n",
    "                img = img[:,:,None]\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        return img\n",
    "\n",
    "    def augment(self, img):\n",
    "        img = img.astype(np.float32)\n",
    "        transformed = self.aug(image = img)\n",
    "        trans_img = transformed[\"image\"]\n",
    "        return trans_img\n",
    "\n",
    "    def normalize_img(self, img):\n",
    "        img = img / 255\n",
    "        return img"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GeM pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gem(x, p = 3, eps = 1e-6):\n",
    "    return F.avg_pool2d(x.clamp(min = eps).pow(p), (x.size(-2), x.size(-1))).pow(1.0 / p)\n",
    "\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p = 3, eps = 1e-6, p_trainable = False):\n",
    "        super(GeM, self).__init__()\n",
    "        if p_trainable:\n",
    "            self.p = Parameter(torch.ones(1) * p)\n",
    "        else:\n",
    "            self.p = p\n",
    "\n",
    "        self.eps = eps\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ret = gem (x, p=self.p, eps=self.eps)\n",
    "        return ret"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, cfg: Any):\n",
    "        super(Net, self).__init__()\n",
    "        self.cfg = cfg\n",
    "        self.n_class = len(cfg.classes)\n",
    "        self.backbone = timm.create_model(cfg.backbone,\n",
    "                                          pretrained = cfg.pretrained,\n",
    "                                          num_classes = 0,\n",
    "                                          global_pool = \"\",\n",
    "                                          in_chans = self.cfg.in_channels)\n",
    "        \n",
    "        backbone_out = self.backbone.feature_info[-1]['num_chs']\n",
    "        self.global_pool = GeM(p_trainable = False)\n",
    "        self.head = torch.nn.Linear(backbone_out, self.n_class)\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, batch):\n",
    "        x = batch['input']\n",
    "        x = self.backbone(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = x[:, :, 0, 0]\n",
    "\n",
    "        logits = self.head(x)\n",
    "\n",
    "        outputs = {}\n",
    "\n",
    "        if self.training:\n",
    "            loss = self.loss_fn(logits, batch[\"target\"].float())\n",
    "            outputs['loss'] = loss\n",
    "\n",
    "        else:\n",
    "            outputs['logits'] = logits\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dl(test_df, cfg):\n",
    "    test_ds = CustomDataset(test_df, cfg, cfg.val_aug)\n",
    "    test_dl = DataLoader(test_ds, shuffle = False, batch_size = cfg.batch_size, num_workers = N_CORES, pin_memory = True)\n",
    "\n",
    "    return test_dl, batch_to_device\n",
    "\n",
    "\n",
    "def get_state_dict(sd_fp):\n",
    "    sd = torch.load(sd_fp, map_location=\"cpu\")\n",
    "    sd = {k.replace(\"module.\", \"\"): v for k, v in sd.items()}\n",
    "    return sd\n",
    "\n",
    "def get_nets(cfg, state_dicts):\n",
    "    nets = []\n",
    "\n",
    "    for i, state_dict in enumerate(state_dicts):\n",
    "        net = Net(cfg).eval.to(DEVICE)\n",
    "        print(\"loading dict\")\n",
    "        sd = get_state_dict(state_dict)\n",
    "        net.load_state_dict(sd, strict = True)\n",
    "        nets += [net]\n",
    "        del sd\n",
    "        gc.collect()\n",
    "    \n",
    "    return nets\n",
    "\n",
    "sub_dl, batch_to_device = get_dl()\n",
    "state_dicts = sorted(glob.glob('/kaggle/input/rsna-seresnext50-5fold/check*.pth'))\n",
    "\n",
    "nets = get_nets(cfg, state_dicts)\n",
    "print(f'Dataloader length : {len(sub_dl.dataset)}')\n",
    "\n",
    "with torch.inference_mode():\n",
    "\n",
    "    preds = [[] for i in range(len(nets))]\n",
    "    for batch in tqdm(sub_dl):\n",
    "        batch = batch_to_device(batch, cfg.device)\n",
    "        for i, net in enumerate(nets):\n",
    "            logits = net(batch)['logits'].sigmoid().float().detach().cpu().numpy()\n",
    "            preds[i] += [logits]\n",
    "\n",
    "preds = np.array([np.concatenate(p, axis = 0) for p in preds])\n",
    "preds = preds.mean(0) #average fold predictions\n",
    "preds = preds[:,0]\n",
    "\n",
    "patient_id = sub_dl.dataset.df['patient_id'].values\n",
    "laterality = sub_dl.dataset.df['laterality'].values\n",
    "\n",
    "prediction_id = [f'{i}_{j}' for i,j in  zip(patient_id, laterality)]\n",
    "\n",
    "pred_df = pd.DataFrame({'prediction_id': prediction_id, 'cancer_raw': preds})\n",
    "\n",
    "#aggregate by prediction_id , i.e. by patient_laterality\n",
    "sub = pred_df.groupby('prediction_id')[['cancer_raw']].agg('mean')\n",
    "sub[['cancer_raw']].to_csv('sub1.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras_cv_attention_models import convnext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_HEIGHT = 1152\n",
    "TARGET_WIDTH  = 1152\n",
    "N_CHANNELS = 1\n",
    "INPUT_SHAPE = (TARGET_HEIGHT, TARGET_WIDTH, N_CHANNELS)\n",
    "TARGET_HEIGHT_WIDTH_RATIO = 1\n",
    "THRESHOLD_BEST = 0.50\n",
    "\n",
    "CLAHE = cv2.createCLAHE(clipLimit = 2.0, tileGridSize = (32, 32))\n",
    "\n",
    "CROP_IMAGE = True\n",
    "APPLY_CLAHE = False\n",
    "APPLY_EQ_HIST = False\n",
    "\n",
    "IMAGE_FORMAT = 'jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    # Repeat channels to create 3 channel images required by pretrained ConvNextV2 models \n",
    "    image = tf.repeat(image, repeats = 3, axis = 3)\n",
    "    # Cast to float 32\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    # Normalize with respect to ImageNet mean/std\n",
    "    image = tf.keras.applications.imagenet_utils.preprocess_input(image, mode='torch')\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def get_model(weightpath):\n",
    "    # Inputs, note the names are equal to the dictionary keys in the dataset\n",
    "    image = tf.keras.layers.Input(INPUT_SHAPE, TARGET_WIDTH, N_CHANNELS)\n",
    "\n",
    "    # Normalize Input\n",
    "    image_norm = normalize(image)\n",
    "\n",
    "    # CNN Feature Maps\n",
    "    x = convnext.ConvNeXtV2Tiny(\n",
    "        input_shape = (TARGET_HEIGHT, TARGET_WIDTH, 3),\n",
    "        pretrained  = None,\n",
    "        num_classes = 0,\n",
    "    )(image_norm)\n",
    "\n",
    "    # Average Pooling BxHxWxC -> BxC\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    # Dropout to prevent Overfitting\n",
    "    x = tf.keras.layers.Dropout(0.30)(x)\n",
    "    # Output value between [0, 1] using Sigmoid function\n",
    "    outputs = tf.keras.layers.Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "    # Define model with inputs and outputs\n",
    "    model = tf.keras.models.Model(inputs = image, outputs = outputs)\n",
    "\n",
    "    # Load pretrained Model Weights\n",
    "    model.load_weights(weightpath)\n",
    "#     model.load_weights('/kaggle/input/rsna-efficientnetv2-training-tensorflow-tpu-ds/model.h5')\n",
    "\n",
    "    # Set model non-trainable\n",
    "    model.trainable = False\n",
    "\n",
    "    # Compile model\n",
    "    model.compile()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained File Path: '/kaggle/input/sartorius-training-dataset/model.h5'\n",
    "tf.keras.backend.clear_session()\n",
    "# enable XLA optmizations\n",
    "tf.config.optimizer.set_jit(True)\n",
    "\n",
    "# model = get_model()\n",
    "modellist = []\n",
    "from keras.models import load_model\n",
    "\n",
    "for ii in [2,3,4]:\n",
    "    model = load_model(f'/kaggle/input/rsnamodel/fold{ii}.h5')\n",
    "    modellist.append(model)\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import (\n",
    "    Dict, Optional, Union, List, Tuple, TYPE_CHECKING, cast, Iterable,\n",
    "    ByteString\n",
    ")\n",
    "from pydicom.valuerep import VR\n",
    "\n",
    "# Binarize the image at the threshold\n",
    "def _binarize(img, threshold):\n",
    "    return (img > threshold).astype(np.uint8)\n",
    "\n",
    "# Get contour points of the breast\n",
    "def _extract_contour(bin_img):\n",
    "    contours, _ = cv2.findContours(\n",
    "        bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    contour = max(contours, key=cv2.contourArea)\n",
    "    return contour\n",
    "\n",
    "\n",
    "# Set to background pixels of the image to zero\n",
    "def _erase_background(img, contour):\n",
    "    mask = np.zeros(img.shape, np.uint8)\n",
    "    cv2.drawContours(mask, [contour], -1, 255, cv2.FILLED)\n",
    "    output = cv2.bitwise_and(img, mask)\n",
    "    return output\n",
    "    \n",
    " # Crop the useless background of the image\n",
    "def img2roi(img):\n",
    "    \n",
    "    # Flip T0 Left/Right Orientation\n",
    "    h0, w0 = img.shape\n",
    "    if img[:,int(-w0 * 0.10):].sum() > img[:,:int(w0 * 0.10)].sum():\n",
    "        img = np.flip(img, axis=1)\n",
    "        \n",
    "        \n",
    "    bin_img = _binarize(img, threshold = 5)\n",
    "    contour = _extract_contour(bin_img)\n",
    "    img = _erase_background(img, contour)\n",
    "    x1, x2 = np.min(contour[:, :, 0]), np.max(contour[:, :, 0])\n",
    "    y1, y2 = np.min(contour[:, :, 1]), np.max(contour[:, :, 1])\n",
    "    x1, x2 = int(0.975 * x1), int(1.025 * x2)\n",
    "    y1, y2 = int(0.975 * y1), int(1.025 * y2)\n",
    "    \n",
    "    x_offset = x2#get_x_offset(image, debug=debug)\n",
    "    offset_bottom, offset_top = y1, y2#get_y_offsets(image[:,:x_offset], debug=debug)\n",
    "    # Crop Height and Width\n",
    "    h_crop = offset_top - offset_bottom\n",
    "    w_crop = x_offset - x1\n",
    "    \n",
    "    # Pad crop offsets to target aspect ratio\n",
    "    # Height too large, pad x offset\n",
    "    if (h_crop / w_crop) > TARGET_HEIGHT_WIDTH_RATIO:\n",
    "#         print('add x')\n",
    "        x_offset += int(h_crop / TARGET_HEIGHT_WIDTH_RATIO - w_crop)\n",
    "    else:\n",
    "#         print('add y')\n",
    "        # Height too small, pad bottom/top offsets\n",
    "        offset_bottom -= int(0.50 * (w_crop * TARGET_HEIGHT_WIDTH_RATIO - h_crop))\n",
    "        offset_bottom_correction = max(0, -offset_bottom)\n",
    "        offset_bottom += offset_bottom_correction\n",
    "\n",
    "        offset_top += int(0.50 * (w_crop * TARGET_HEIGHT_WIDTH_RATIO - h_crop))\n",
    "        offset_top += offset_bottom_correction\n",
    "        \n",
    "    # Crop Image\n",
    "#     image = image[offset_bottom:offset_top:,:x_offset]\n",
    "    \n",
    "    return img[offset_bottom: offset_top, x1: x_offset]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "SUBMISSION_ROWS = []\n",
    "# Iterate over all patient_id/laterality combinations groups\n",
    "for idx, ((patient_id, laterality), g) in enumerate(tqdm(test.groupby(['patient_id', 'laterality']))):\n",
    "    # Cancer target is mean of predicted cancer values\n",
    "    cancer = []#0\n",
    "    # Iterate over all scans in group\n",
    "    for row_idx, row in g.iterrows():\n",
    "        # Load Image\n",
    "        image_id = row['image_id']\n",
    "        image = cv2.imread(f'{SAVE_FOLDER}/{patient_id}_{image_id}.png', cv2.IMREAD_GRAYSCALE)\n",
    "        image = img2roi(image)\n",
    "        image = cv2.resize(image, (SAVE_SIZE,SAVE_SIZE), interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        \n",
    "        # Show First Few Images\n",
    "        if idx < 16:\n",
    "            plt.figure(figsize=(5,8))\n",
    "            plt.imshow(image)\n",
    "            plt.show()\n",
    "        \n",
    "        # Expand to Batch HxW -> 1xHxWx1\n",
    "        image = np.expand_dims(image, [0, 3])\n",
    "        # Make Prediction\n",
    "        \n",
    "        for model in modellist:\n",
    "            cancer.append(model.predict_on_batch(image).squeeze() / len(g) /len(modellist))\n",
    "    \n",
    "#         cancer += model.predict_on_batch(image).squeeze() / len(g)\n",
    "        # Remove Image\n",
    "#         os.remove(f'{SAVE_FOLDER}/{patient_id}_{image_id}.png')\n",
    "        \n",
    "    # Add Submission Row\n",
    "    SUBMISSION_ROWS.append({\n",
    "        'prediction_id': f'{patient_id}_{laterality}',\n",
    "        'cancer_raw': np.median(cancer),\n",
    "    })\n",
    "    \n",
    "    if np.random.rand() > 0.99:\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame from submission rows\n",
    "submission_df = pd.DataFrame(SUBMISSION_ROWS)\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarize predictions\n",
    "th = np.quantile(submission_df['cancer_raw'].values,0.97935)\n",
    "# th = THRESHOLD_BEST.copy()\n",
    "print('THRESHOLD_BEST:',th)\n",
    "\n",
    "# submission_df['cancer'] = (submission_df['cancer_raw'].values > th).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df[['prediction_id','cancer_raw']].to_csv('sub2.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge two results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1 = pd.read_csv('sub1.csv')\n",
    "sub2 = pd.read_csv('sub2.csv')\n",
    "sub = pd.merge(sub1,sub2,how='left',on='prediction_id')\n",
    "sub.columns = ['prediction_id','cancer_raw_1','cancer_raw_2']\n",
    "sub['cancer_raw'] = sub['cancer_raw_1'].rank(pct = True) * 0.5 + sub['cancer_raw_2'].rank(pct = True) * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = np.quantile(sub['cancer_raw'].values,0.97935)\n",
    "sub['cancer'] = (sub['cancer_raw'].values > th).astype(int)\n",
    "sub[['prediction_id','cancer']].to_csv('submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
